<!DOCTYPE HTML>
<!--
    Dopetrope by HTML5 UP
    html5up.net | @ajlkn
    Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>
    <head>
        <title>NARF22: Neural Articulated Radiance Fields</title>
        <meta charset="utf-8" />
        <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
        <link rel="stylesheet" href="../../assets/css/main.css" />
        <link rel="shortcut icon" type="image/png" href="../../images/logo/LFP_logo_final_JustHand_Blue.png"/>
    </head>

    <body class="homepage is-preload">
        <div id="page-wrapper">

            <section id="header">
                <!-- Logo -->
                <div class="logo"><a href="https://progress.eecs.umich.edu/"><img src="../../images/logo/two_tone_standard.svg" alt="" /></a></div>
            </section>

            <section id="main">
                <div class="container">

                    <!-- Content -->
                    <article class="box post project">
                        <!-- TITLE -->
                        <header>
                            <h2>NARF22: Neural Articulated Radiance Fields for Configuration-Aware Rendering</h2>
                        </header>

                        <!-- AUTHORS -->
                        <div class="row aln-center project-authors">
                            <div class="col-3 col-4-large col-4-medium col-6-small project-author">
                                <h3>Stanley Lewis</h3>
                                <p>University of Michigan</p>
                            </div>
                            <div class="col-3 col-4-large col-4-medium col-6-small project-author">
                                <h3><a href="http://janapavlasek.com/">Jana Pavlasek</a></h3>
                                <p>University of Michigan</p>
                            </div>
                            <div class="col-3 col-4-large col-4-medium col-6-small project-author">
                                <h3><a href="https://web.eecs.umich.edu/~ocj/">Odest Chadwicke Jenkins</a></h3>
                                <p>University of Michigan</p>
                            </div>
                        </div>

                        <!-- Pitch image. -->
                        <div class="image pitch centered"><img src="images/pitch.png" alt="" /></div>

                        <!-- ABSTRACT -->
                        <div class="abstract">
                            <p>
                                Articulated objects pose a unique challenge for robotic perception and manipulation. Their increased number of degrees-of-freedom makes tasks such as localization computationally difficult, while also making the process of real-world dataset collection unscalable. With the aim of addressing these scalability issues, we propose Neural Articulated Radiance Fields (NARF22), a pipeline which uses a fully-differentiable, configuration-parameterized Neural Radiance Field (NeRF) as a means of providing high quality renderings of articulated objects. NARF22 requires no explicit knowledge of the object structure at inference time. We propose a two-stage parts-based training mechanism which allows the object rendering models to generalize well across the configuration space even if the underlying training data has as few as one configuration represented. We demonstrate the efficacy of NARF22 by training configurable renderers on a real-world articulated tool dataset collected via a Fetch mobile manipulation robot. We show the applicability of the model to gradient-based inference methods through a configuration estimation and 6 degree-of-freedom pose refinement task.
                            </p>
                        </div>

                        <!-- Links. -->
                        <div class="paperlinks">
                            <p>
                                <a href="https://arxiv.org/abs/2210.01166"><i class="far fa-file-pdf"></i> Read the Paper</a> &nbsp;&nbsp;
                                <!-- Optional. -->
                                <!-- <a href="#"><i class="fas fa-chalkboard-teacher"></i> Watch the Talk</a> -->
                            </p>
                        </div>

                    </article>

                    <article class="box post exp">
                        <header>
                            <h2>Configuration-Aware Renderings</h2>
                        </header>

                        <p>
                            NARF is trainined using labelled training images containing object poses, masks, and ground truth configurations.
                            The articulation model of the object is required at training time.
                            At testing time, NARF can render images of articulated objects at arbitrary poses and articulations.
                        </p>

                        <p>
                            The following are examples of NARF configuration-aware renderings of articulated objects from the <a href="../tool-parts/index.html">Progress Tools dataset</a>.
                            These models were trained with only a small number of example configurations in the training data.
                        </p>

                        <div class="row aln-center">
                            <div class="col-3">
                                <div class="image centered">
                                    <img src="images/articulations/clamp.gif" alt="" />
                                </div>
                            </div>
                            <div class="col-3">
                                <div class="image centered">
                                    <img src="images/articulations/red_pliers.gif" alt="" />
                                </div>
                            </div>
                            <div class="col-3">
                                <div class="image centered">
                                    <img src="images/articulations/grey_pliers.gif" alt="" />
                                </div>
                            </div>
                            <div class="col-3">
                                <div class="image centered">
                                    <img src="images/articulations/longnose_pliers.gif" alt="" />
                                </div>
                            </div>
                        </div>
                    </article>

                    <article class="box post exp">
                        <header>
                            <h2>Pose &amp; Configuration Refinement</h2>
                        </header>

                        <p>
                            The NARF rendering pipeline is fully differentiable.
                            We perform 6 DoF pose and configuration refinement by computing Mean Squared Error loss between the rendering at an initial hypothesis and the observation image.
                            The initial pose and configuration is then refined iteratively through Stochastic Gradient Descent using the gradient of the MSE loss.
                        </p>

                        <p>
                            In the examples below, the 6 DoF pose of the clamp is initialized to an estimate given by an external module.
                            The configuration of the clamp is initialized randomly within its articulation constraints.
                            We are able to recover the configuration and refine the 6 DoF pose using SGD over the gradients of the NARF model.
                        </p>

                        <div class="slideshow-container">
                            <div class="image-slideshow-container">
                                <div class="image slideshow"><img src="images/pose/3_config.gif" alt="" /></div>
                                <div class="image slideshow"><img src="images/pose/4_config.gif" alt="" /></div>
                                <div class="image slideshow"><img src="images/pose/5_config.gif" alt="" /></div>
                                <div class="image slideshow"><img src="images/pose/6_config.gif" alt="" /></div>
                                <div class="image slideshow"><img src="images/pose/10_config.gif" alt="" /></div>

                                <a class="prev" onclick="plusSlides(-1)">&#10094;</a>
                                <a class="next" onclick="plusSlides(1)">&#10095;</a>
                            </div>

                            <!-- The dots/circles -->
                            <div style="text-align:center">
                              <span class="dot" onclick="currentSlide(1)"></span>
                              <span class="dot" onclick="currentSlide(2)"></span>
                              <span class="dot" onclick="currentSlide(3)"></span>
                              <span class="dot" onclick="currentSlide(4)"></span>
                              <span class="dot" onclick="currentSlide(5)"></span>
                            </div>
                        </div>

                    </article>

                    <!-- <article class="box post"> -->
                        <!-- <header> -->
                            <!-- <h2>Video</h2> -->
                        <!-- </header> -->

                        <!-- Link to video on YouTube. -->
                        <!-- To get your video link, go to your video and click "Share" -> "Embed" to get this iframe.
                             You can remove width and height. -->
                        <!-- <div class="video-container"> -->
                            <!-- <iframe class="video" src="https://www.youtube.com/embed/videoseries?list=PLDutmfAv2lfYZzuxA9BT9Y6rvCofTAGuc" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe> -->
                        <!-- </div> -->
                    <!-- </article> -->

                    <!-- <article class="box post"> -->
                        <!-- <header> -->
                            <!-- <h2>Citation</h2> -->
                        <!-- </header> -->

                        <!-- The whitespace between <pre> tags will be preserved exactly how it is in the code. -->
                        <!-- <div class="citation"> -->
<!-- <pre><code>@inproceedings{tag, -->
  <!-- author = {Last, First and Last, First and ...}, -->
  <!-- title = {Paper title}, -->
  <!-- year = {2020}, -->
  <!-- ... -->
<!-- }</code></pre> -->
                        <!-- </div> -->
                    <!-- </article> -->

                <!-- </div> -->
            </section>

            <section id="footer">

                <!-- Copyright -->
                <div id="copyright">
                    <ul class="links">
                        <li>&copy; 2022. All rights reserved.</li><li>Design: Dopetrope by
                    <a href="http://twitter.com/ajlkn">AJ</a> for <a href="http://html5up.net/">HTML5 UP</li>
                    </ul>
                </div>

            </section>

        </div>

        <!-- Scripts -->
        <script src="../../assets/js/jquery.min.js"></script>
        <script src="../../assets/js/carousel.js"></script>
        <script>
            (function($) {
                carousel(slideIndex, 8000);
            })(jQuery);
        </script>

    </body>
</html>
